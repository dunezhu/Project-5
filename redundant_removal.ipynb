{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xsnTsiQRPCXC"
      },
      "outputs": [],
      "source": [
        "# Import 'modified.docx'  \n",
        "!pip install python-docx\n",
        "import docx\n",
        "from google.colab import files\n",
        "\n",
        "# Select the Word file from your Local Machine\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Open the Word file\n",
        "doc = docx.Document(list(uploaded.keys())[0]) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9iGZ-OXn0pcp"
      },
      "outputs": [],
      "source": [
        "# [BASE LAYER SPECIFIC]: Check if the line is equal to the base URL and applicable outer URL(s) and delete for the -1st and PRECURSIVE LAYERS\n",
        "keywords = [\n",
        "\n",
        " \"'https://www.website.suffix/'\", \"'https://www.website.suffix'\", \"'https://'\"\n",
        "\n",
        "    ]\n",
        "\n",
        "# Iterate through the paragraphs of the document\n",
        "for para in doc.paragraphs:\n",
        "    for keyword in keywords:\n",
        "        if keyword in para.text:\n",
        "            # If the keyword is found in the paragraph, remove it\n",
        "            para.text = para.text.replace(keyword, \"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W7ewKW3B0bsC"
      },
      "outputs": [],
      "source": [
        "# [SUBSEQUENT LAYER SPECIFIC] : Define a list of recursive URLs to delete for the [Nth] LAYERS URL LIST SEARCH\n",
        "keywords = [\n",
        "\n",
        "#BASE LAYER\n",
        " \n",
        "        ]\n",
        "\n",
        "# Iterate through the paragraphs of the document\n",
        "for para in doc.paragraphs:\n",
        "    for keyword in keywords:\n",
        "        if keyword in para.text:\n",
        "            # If the keyword is found in the paragraph, remove it\n",
        "            para.text = para.text.replace(keyword, \"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Hu0e2pZ7mHC"
      },
      "outputs": [],
      "source": [
        "# [SUBSEQUENT LAYER SPECIFIC] : Define a list of recursive URLs to delete for the [Nth] LAYERS URL LIST SEARCH\n",
        "keywords = [\n",
        "\n",
        "#2nd LAYER\n",
        "  \n",
        "        ]\n",
        "\n",
        "# Iterate through the paragraphs of the document\n",
        "for para in doc.paragraphs:\n",
        "    for keyword in keywords:\n",
        "        if keyword in para.text:\n",
        "            # If the keyword is found in the paragraph, remove it\n",
        "            para.text = para.text.replace(keyword, \"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sj2WdgKB_Qqc"
      },
      "outputs": [],
      "source": [
        "# [SUBSEQUENT LAYER SPECIFIC] : Define a list of recursive URLs to delete for the [Nth] LAYERS URL LIST SEARCH\n",
        "keywords = [\n",
        "\n",
        "#3rd LAYER\n",
        "   \n",
        "        ]\n",
        "\n",
        "# Iterate through the paragraphs of the document\n",
        "for para in doc.paragraphs:\n",
        "    for keyword in keywords:\n",
        "        if keyword in para.text:\n",
        "            # If the keyword is found in the paragraph, remove it\n",
        "            para.text = para.text.replace(keyword, \"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zR4jc5WJSYnE"
      },
      "outputs": [],
      "source": [
        "# [SUBSEQUENT LAYER SPECIFIC] : Define a list of recursive URLs to delete for the [Nth] LAYERS URL LIST SEARCH\n",
        "keywords = [\n",
        "\n",
        "#4th LAYER\n",
        "\n",
        "  \n",
        "        ]\n",
        "\n",
        "# Iterate through the paragraphs of the document\n",
        "for para in doc.paragraphs:\n",
        "    for keyword in keywords:\n",
        "        if keyword in para.text:\n",
        "            # If the keyword is found in the paragraph, remove it\n",
        "            para.text = para.text.replace(keyword, \"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MgP_2sMXxYk8"
      },
      "outputs": [],
      "source": [
        "# [SUBSEQUENT LAYER SPECIFIC] : Define a list of recursive URLs to delete for the [Nth] LAYERS URL LIST SEARCH\n",
        "keywords = [\n",
        "\n",
        "#5th LAYER\n",
        "\n",
        "   \n",
        "        ]\n",
        "\n",
        "# Iterate through the paragraphs of the document\n",
        "for para in doc.paragraphs:\n",
        "    for keyword in keywords:\n",
        "        if keyword in para.text:\n",
        "            # If the keyword is found in the paragraph, remove it\n",
        "            para.text = para.text.replace(keyword, \"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AsES6Ke60dFX"
      },
      "outputs": [],
      "source": [
        "# ADD NTH LAYERS FORWARD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "db09hQ-T1DcK"
      },
      "outputs": [],
      "source": [
        "# Save the changes to a modified document\n",
        "doc.save('modified.docx')\n",
        "\n",
        "# Download the modified Word file\n",
        "files.download('modified.docx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SeY0OQAB1ao8"
      },
      "outputs": [],
      "source": [
        "#RENAME 'modified.docx' TO USE IN 'alpha'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TOy5Ffk40513"
      },
      "outputs": [],
      "source": [
        "# Add , after all entries beginning in '\n",
        "for para in doc.paragraphs:\n",
        "    if para.text.startswith(\"'\"):\n",
        "        para.text += \",\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BHfCv0xO1-fT"
      },
      "outputs": [],
      "source": [
        "# Save the changes to a modified document\n",
        "doc.save('modified.docx')\n",
        "\n",
        "# Download the modified Word file\n",
        "files.download('modified.docx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YEbOohF02X-T"
      },
      "outputs": [],
      "source": [
        "# Convert the Word file to a Text file and download\n",
        "!pip install docx2txt\n",
        "from google.colab import files\n",
        "import docx2txt\n",
        "\n",
        "# Upload the word document from the desktop\n",
        "uploaded = files.upload()\n",
        "\n",
        "for name, data in uploaded.items():\n",
        "    with open(name, 'wb') as f:\n",
        "        f.write(data)\n",
        "    print(f'File \"{name}\" was imported successfully!')\n",
        "    \n",
        "    # Extract text from the word document\n",
        "    text = docx2txt.process(name)\n",
        "\n",
        "    # Remove blank spaces and newline characters\n",
        "    text = text.replace(\"\\n\", \" \")\n",
        "    text = \" \".join(text.split())\n",
        "\n",
        "    # Save the text to a file\n",
        "    with open(name+\".txt\", \"w\") as text_file:\n",
        "        text_file.write(text)\n",
        "        \n",
        "    # Download the text file\n",
        "    files.download(name+\".txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m3Ya8umg2Y-c"
      },
      "outputs": [],
      "source": [
        "#UPDATE 'urls' IN 'search'  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pQwtDpqE17pN"
      },
      "outputs": [],
      "source": [
        "# [alpha.ipynb]\n",
        "# Import RENAMED 'modified.docx'  \n",
        "\n",
        "!pip install python-docx\n",
        "import docx\n",
        "from google.colab import files\n",
        "\n",
        "# Select the Word file from your Local Machine\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Open the Word file\n",
        "doc = docx.Document(list(uploaded.keys())[0]) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sn9EtwKfLE5D"
      },
      "outputs": [],
      "source": [
        "# Add '\"' to all entries beginning in \"'\"\n",
        "for para in doc.paragraphs:\n",
        "    if para.text.startswith(\"'\"):\n",
        "        para.text = '\"' + para.text\n",
        "\n",
        "# Add '\"' after all entries beginning in '\"'\n",
        "for para in doc.paragraphs:\n",
        "    if para.text.startswith('\"'):\n",
        "        para.text += '\"' "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bqUKbBwzPBEV"
      },
      "outputs": [],
      "source": [
        "# Add ',' after all entries beginning in '\"'\n",
        "for para in doc.paragraphs:\n",
        "    if para.text.startswith('\"'):\n",
        "        para.text += \",\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wweEAfG-WL4n"
      },
      "outputs": [],
      "source": [
        "# Save the changes to a modified document\n",
        "doc.save('modified.docx')\n",
        "\n",
        "# Download the modified Word file\n",
        "files.download('modified.docx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qNYc6spkNwBF"
      },
      "outputs": [],
      "source": [
        "# Convert the Word file to a Text file and download\n",
        "!pip install docx2txt\n",
        "from google.colab import files\n",
        "import docx2txt\n",
        "\n",
        "# Upload the word document from the desktop\n",
        "uploaded = files.upload()\n",
        "\n",
        "for name, data in uploaded.items():\n",
        "    with open(name, 'wb') as f:\n",
        "        f.write(data)\n",
        "    print(f'File \"{name}\" was imported successfully!')\n",
        "    \n",
        "    # Extract text from the word document\n",
        "    text = docx2txt.process(name)\n",
        "\n",
        "    # Remove blank spaces and newline characters\n",
        "    text = text.replace(\"\\n\", \" \")\n",
        "    text = \" \".join(text.split())\n",
        "\n",
        "    # Save the text to a file\n",
        "    with open(name+\".txt\", \"w\") as text_file:\n",
        "        text_file.write(text)\n",
        "        \n",
        "    # Download the text file\n",
        "    files.download(name+\".txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8qVolB3u7UBk"
      },
      "outputs": [],
      "source": [
        "#UPDATE 'keywords' "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMsrlA6pvrQdwaSwuZMGLBc"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}